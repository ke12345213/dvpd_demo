# gpu config
accelerator: gpu
devices: [0,1,2,3]

# log config
log_dir: 
resume:  null  # if want to resume, specify ckpt path

# inference config
ckpt_path:  # null

# dataset config
dataset_config:
  batch_size: 4
  cut_len: 32640  # length of training samples: 4s
  num_workers: 16  # dataloader workers
  train_src_dir: 
  train_tgt_dir: 
  val_src_dir:
  val_tgt_dir:
  test_src_dir: 
  test_tgt_dir: 

# training config
max_epochs: 200
val_check_interval: 1.0  # validate every epochs
gradient_clip_val: 5.0
opt:
  lr: 1.0e-3
sch:
  step_size: 2  
  gamma: 0.97
  verbose: true
ema_config:
  decay: 0.999



# model config
model_config:
  num_channels: 24
  temb_dim: 256
  n_blocks: 3
  n_heads: 4
  dropout_p: 0.1
  n_fft: 512 # 512
  hop_length: 128 # 192


# SDE config
train_sde_config:
  k: 2.6
  c: 0.51
  Trs: 0.999
  T: 1.0
  N: 25
  t_eps: 0.01
  n_steps: 0
  snr: 0.5
test_sde_config:
  k: 2.6
  c: 0.51
  Trs: 0.12
  T: 1.0
  N: 3
  t_eps: 0.01
  n_steps: 0
  snr: 0.5
p_g_alpha: 0.4

